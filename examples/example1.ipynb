{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with dictionaries and word embeddings\n",
    "\n",
    "## Example\n",
    "\n",
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reichv\\AppData\\Local\\Continuum\\anaconda3\\envs\\weelex\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# imports:\n",
    "import pandas as pd\n",
    "\n",
    "from weelex import WEELexClassifier\n",
    "from weelex import Lexicon\n",
    "from weelex import Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  2.1 Dictionary/Lexicon \n",
    "\n",
    "- We need `Lexicon` objects.\n",
    "- These can be in different formats:\n",
    "    - tabular:\n",
    "        -  `pandas.DataFrame`where each column is one of the categories and each row is the words for that category\n",
    "        - `.csv` file path with data of the same format\n",
    "    - Key-value pairs:\n",
    "        - `dict` of the form `{'category1':['term1', 'term2'], 'category2': ['term3', 'term4', 'term5']}`\n",
    "        - `.json` file path with data of the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          PolitikVR            AutoVR\n",
       "0        Demokratie           schnell\n",
       "1            Regime              Auto\n",
       "2      demokratisch         Automobil\n",
       "3         Parlament         Autobauer\n",
       "4         Bundestag          Mercedes\n",
       "5            Partei               BMW\n",
       "6          Parteien           Porsche\n",
       "7           Politik              Audi\n",
       "8       Politikerin                VW\n",
       "9         Politiker           Lenkrad\n",
       "10             Wahl            Felgen\n",
       "11           wählen            Reifen\n",
       "12         Kandidat            Straße\n",
       "13       Wiederwahl                PS\n",
       "14        Präsident           Auspuff\n",
       "15        Kanzlerin              Lack\n",
       "16          Kanzler             Kombi\n",
       "17  Bundespräsident               Bus\n",
       "18         Minister        Ledersitze\n",
       "19      Ministerien            Fahrer\n",
       "20      Ministerium           Faherin\n",
       "21     populistisch   Geschwindigkeit\n",
       "22           rechts            Bolide\n",
       "23            links        Karosserie\n",
       "24       Opposition                Km\n",
       "25       Korruption           Fenster\n",
       "26          Neuwahl              Hupe\n",
       "27          Landtag     Pferdestärken\n",
       "28    Verhandlungen             Motor\n",
       "29        Beschluss  Elektromobilität\n",
       "30     beschliessen             Tesla\n",
       "31     Steuergelder            Hybrid\n",
       "32            Staat            Toyota\n",
       "33      Abgeordnete       Lamborghini\n",
       "34           Wähler               KFZ\n",
       "35         Wählerin          Benziner\n",
       "36        Regierung            Benzin\n",
       "37         regieren            Diesel\n",
       "38   Parteiprogramm      Führerschein\n",
       "39        Koalition          Fahrzeug\n",
       "40       Ministerin             rasen\n",
       "41              NaN           Strecke\n",
       "42              NaN            tanken\n",
       "43              NaN              Jeep\n",
       "44              NaN               SUV\n",
       "45              NaN         Verbrauch\n",
       "46              NaN           Antrieb\n",
       "47              NaN          Zylinder\n",
       "48              NaN            Garage\n",
       "49              NaN           Hubraum\n",
       "50              NaN         Innenraum\n",
       "51              NaN        Kofferraum\n",
       "52              NaN          Drehzahl\n",
       "53              NaN     Handschuhfach\n",
       "54              NaN           Verdeck"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabular data:\n",
    "df1 = pd.read_csv('examplefiles/mylex1.csv', sep=';', encoding='latin1')\n",
    "lex1 = Lexicon(df1)\n",
    "# or:\n",
    "lex1 = Lexicon('examplefiles/mylex1.csv', sep=';', encoding='latin1')\n",
    "lex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Space     Food\n",
       "0          ab     Brot\n",
       "1     abseits   Kuchen\n",
       "2   abstaende  GemÃ¼se\n",
       "3     abstand      NaN\n",
       "4   abstÃ¤nde      NaN\n",
       "5    abwaerts      NaN\n",
       "6    abwÃ¤rts      NaN\n",
       "7          an      NaN\n",
       "8  anstellung      NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mappings/key-value pairs:\n",
    "lex2 = Lexicon('examplefiles/mylex2.json')\n",
    "lex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, different lexica can be combined into one, for example if different dictionary sources are considered/required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          PolitikVR            AutoVR       Space     Food\n",
       "0        Demokratie           schnell          ab     Brot\n",
       "1            Regime              Auto     abseits   Kuchen\n",
       "2      demokratisch         Automobil   abstaende  GemÃ¼se\n",
       "3         Parlament         Autobauer     abstand      NaN\n",
       "4         Bundestag          Mercedes   abstÃ¤nde      NaN\n",
       "5            Partei               BMW    abwaerts      NaN\n",
       "6          Parteien           Porsche    abwÃ¤rts      NaN\n",
       "7           Politik              Audi          an      NaN\n",
       "8       Politikerin                VW  anstellung      NaN\n",
       "9         Politiker           Lenkrad         NaN      NaN\n",
       "10             Wahl            Felgen         NaN      NaN\n",
       "11           wählen            Reifen         NaN      NaN\n",
       "12         Kandidat            Straße         NaN      NaN\n",
       "13       Wiederwahl                PS         NaN      NaN\n",
       "14        Präsident           Auspuff         NaN      NaN\n",
       "15        Kanzlerin              Lack         NaN      NaN\n",
       "16          Kanzler             Kombi         NaN      NaN\n",
       "17  Bundespräsident               Bus         NaN      NaN\n",
       "18         Minister        Ledersitze         NaN      NaN\n",
       "19      Ministerien            Fahrer         NaN      NaN\n",
       "20      Ministerium           Faherin         NaN      NaN\n",
       "21     populistisch   Geschwindigkeit         NaN      NaN\n",
       "22           rechts            Bolide         NaN      NaN\n",
       "23            links        Karosserie         NaN      NaN\n",
       "24       Opposition                Km         NaN      NaN\n",
       "25       Korruption           Fenster         NaN      NaN\n",
       "26          Neuwahl              Hupe         NaN      NaN\n",
       "27          Landtag     Pferdestärken         NaN      NaN\n",
       "28    Verhandlungen             Motor         NaN      NaN\n",
       "29        Beschluss  Elektromobilität         NaN      NaN\n",
       "30     beschliessen             Tesla         NaN      NaN\n",
       "31     Steuergelder            Hybrid         NaN      NaN\n",
       "32            Staat            Toyota         NaN      NaN\n",
       "33      Abgeordnete       Lamborghini         NaN      NaN\n",
       "34           Wähler               KFZ         NaN      NaN\n",
       "35         Wählerin          Benziner         NaN      NaN\n",
       "36        Regierung            Benzin         NaN      NaN\n",
       "37         regieren            Diesel         NaN      NaN\n",
       "38   Parteiprogramm      Führerschein         NaN      NaN\n",
       "39        Koalition          Fahrzeug         NaN      NaN\n",
       "40       Ministerin             rasen         NaN      NaN\n",
       "41              NaN           Strecke         NaN      NaN\n",
       "42              NaN            tanken         NaN      NaN\n",
       "43              NaN              Jeep         NaN      NaN\n",
       "44              NaN               SUV         NaN      NaN\n",
       "45              NaN         Verbrauch         NaN      NaN\n",
       "46              NaN           Antrieb         NaN      NaN\n",
       "47              NaN          Zylinder         NaN      NaN\n",
       "48              NaN            Garage         NaN      NaN\n",
       "49              NaN           Hubraum         NaN      NaN\n",
       "50              NaN         Innenraum         NaN      NaN\n",
       "51              NaN        Kofferraum         NaN      NaN\n",
       "52              NaN          Drehzahl         NaN      NaN\n",
       "53              NaN     Handschuhfach         NaN      NaN\n",
       "54              NaN           Verdeck         NaN      NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex = lex1.merge(lex2, inplace=False)\n",
    "lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Embeddings\n",
    "\n",
    "- Pretrained embedding vectors need to be provided. In the future, the will be support for self-training or fine tuning.\n",
    "- Pretrained FastText Vectors can be downloaded on the official website: \n",
    "    - [https://fasttext.cc/docs/en/crawl-vectors.html](https://fasttext.cc/docs/en/crawl-vectors.html)\n",
    "    - Here, we download the German vectors with the `bin` version.\n",
    "    - store these somewhere\n",
    "    - the file is several `GB` large $\\rightarrow$ dowloading the file and loading it into memory may take some time\n",
    "    - the file is compressed after download (`.bin.gz`). This is fine. It does not need to be uncompressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_embeddings = '../../cc.de.300.bin'  # change this to your saved location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = Embeddings()\n",
    "embeds.load_vectors(path_to_embeddings, embedding_type='fasttext', fine_tuned=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding object can be filtered such that it only contains the words that are in the dictionary, which is sufficient for the method.\n",
    "The filtered embeddings can be saved and in subsequent sessions these can be loaded which reduces the required memory and loading times in subsequent operations.\n",
    "This is particularly valuable in case you need to work on the following steps of the classification over multiple days and sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds.filter_terms(lex.vocabulary)\n",
    "\n",
    "# saving\n",
    "path_to_filtered_embeddings = './filtered_embeddings'\n",
    "embeds.save_filtered(path_to_filtered_embeddings)\n",
    "del embeds\n",
    "\n",
    "# create new embeds instance and load the filtered vectors\n",
    "embeds = Embeddings()\n",
    "embeds.load_filtered(path_to_filtered_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the model on the dictionary\n",
    "\n",
    "- The method works by first training a machine learning ensemble on the dictionary.\n",
    "- It is possible to provide `main_keys`, i.e. the categories to predict, and `support_keys`, i.e. other categories you do not want a prediction for but provide terms anyhow\n",
    "- including `support_keys` can improve the classification because it allows the model to differentiate more words\n",
    "- by default, all the keys of your `Lexicon` instance are main keys. But this can be changed with the `main_keys` and `support_keys` parameter. Alternatively, it is possible to provide a `Lexicon` instance via the `lex` parameter for main categories and another `Lexicon` via the `support_lex` parameter for support categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = WEELexClassifier(embeds=embeds,\n",
    "                              relevant_pos=['NOUN'],\n",
    "                              min_df=1,  # Optional. Selected in able to run on small example. Better to have higher value. Default is 5\n",
    "                              max_df=0.99,  # Optional. Selected in able to run on small example. Default is 0.95\n",
    "                              n_docs=20,  # Optional. Selected to run on small example. Ideally, use the length of your data.\n",
    "                              n_words=10  # Optional. Selected to run on small example. Default is 40000\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PolitikVR', 'AutoVR', 'Space', 'Food']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tune the machine learning model, we specify a grid of hyperparameters\n",
    "# this will be searched via RandomizedSearch\n",
    "# This grid is very basic with only 6 possible combinations. It is only\n",
    "# used for this example and should be expanded upon in a real setting.\n",
    "param_grid = [{'modeltype': ['svm'],\n",
    "            'n_models': [2],\n",
    "            'pca': [10, None],\n",
    "            'svc_c': [0.1, 1, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reichv\\AppData\\Local\\Continuum\\anaconda3\\envs\\weelex\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 6 is smaller than n_iter=150. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sets of parameters:\n",
      "    0: {'input_shape': 300, 'svc_c': 0.1, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n",
      "    1: {'input_shape': 300, 'svc_c': 1, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n",
      "    2: {'input_shape': 300, 'svc_c': 10, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reichv\\AppData\\Local\\Continuum\\anaconda3\\envs\\weelex\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 6 is smaller than n_iter=150. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sets of parameters:\n",
      "    0: {'input_shape': 300, 'svc_c': 0.1, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n",
      "    1: {'input_shape': 300, 'svc_c': 1, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n",
      "    2: {'input_shape': 300, 'svc_c': 10, 'pca': 10, 'n_models': 2, 'modeltype': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "classifier.weelexfit(lex=lex,\n",
    "                     support_lex=None,  # entire support lexicon can be passed instead of the 'support_keys' parameter\n",
    "                     main_keys=['PolitikVR', 'AutoVR'],  # optional. Uses all keys of lex if None\n",
    "                     support_keys=['Space', 'Food'],  # optional. Is not used if None\n",
    "                     hp_tuning=True,  # Hyperparameter tuning -> use for best results\n",
    "                     param_grid=param_grid,  # Hyperparameter grid for hp tuning\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Predict a body of texts:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Texts to predict in this example:\n",
    "data = pd.Series(\n",
    "    [\n",
    "    'Ich esse gerne Kuchen und andere Süßigkeiten',\n",
    "    'Dort steht ein schnelles Auto mit einem Lenkrad und Reifen.',\n",
    "    'Die Politik von heute ist nicht mehr die gleiche wie damals.',\n",
    "    'Hier ist nochmal ein sehr generischer Satz.',\n",
    "    'Wie ist das Wetter heute?',\n",
    "    'Ich esse gerne Kuchen und andere Süßigkeiten',\n",
    "    'Dort steht ein schnelles Auto mit einem Lenkrad und Reifen.',\n",
    "    'Die Politik von heute ist nicht mehr die gleiche wie damals.',\n",
    "    'Hier ist nochmal ein sehr generischer Satz.',\n",
    "    'Wie ist das Wetter heute?',\n",
    "    'Ich esse gerne Kuchen und andere Süßigkeiten',\n",
    "    'Dort steht ein schnelles Auto mit einem Lenkrad und Reifen.',\n",
    "    'Die Politik von heute ist nicht mehr die gleiche wie damals.',\n",
    "    'Hier ist nochmal ein sehr generischer Satz.',\n",
    "    'Wie ist das Wetter heute?',\n",
    "    'Ich esse gerne Kuchen und andere Süßigkeiten',\n",
    "    'Dort steht ein schnelles Auto mit einem Lenkrad und Reifen.',\n",
    "    'Die Politik von heute ist nicht mehr die gleiche wie damals.',\n",
    "    'Hier ist nochmal ein sehr generischer Satz.',\n",
    "    'Wie ist das Wetter heute?',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit vectorizer\n",
      "Time to vectorize: 0.00 minutes\n",
      "'Süßigkeit' is not in list\n",
      "Returning null vector instead\n",
      "'Reife' is not in list\n",
      "Returning null vector instead\n",
      "'Satz' is not in list\n",
      "Returning null vector instead\n",
      "'Wetter' is not in list\n",
      "Returning null vector instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PolitikVR</th>\n",
       "      <th>AutoVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PolitikVR  AutoVR\n",
       "0           0       1\n",
       "1           0       1\n",
       "2           1       0\n",
       "3           0       0\n",
       "4           0       0\n",
       "5           0       1\n",
       "6           0       1\n",
       "7           1       0\n",
       "8           0       0\n",
       "9           0       0\n",
       "10          0       1\n",
       "11          0       1\n",
       "12          1       0\n",
       "13          0       0\n",
       "14          0       0\n",
       "15          0       1\n",
       "16          0       1\n",
       "17          1       0\n",
       "18          0       0\n",
       "19          0       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.weelexpredict(data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('weelex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18fadc8bf522f865c89552f3439cd3acae47c651b1f907d5d8c80e137e4c93af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
