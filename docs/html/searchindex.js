Search.setIndex({"docnames": ["index", "weelex"], "filenames": ["index.rst", "weelex.rst"], "titles": ["Welcome to Weelex\u2019s documentation!", "weelex package"], "terms": {"index": 0, "modul": 0, "search": 0, "page": 0, "contain": 1, "main": 1, "class": 1, "weelexclassifi": 1, "emb": 1, "dict": 1, "str": 1, "basictfidf": 1, "none": 1, "ctfidf": 1, "clustertfidfvector": 1, "use_ctfidf": 1, "bool": 1, "true": 1, "word_level_aggreg": 1, "test_siz": 1, "float": 1, "random_st": 1, "int": 1, "n_job": 1, "1": 1, "progress_bar": 1, "fals": 1, "relevant_po": 1, "list": 1, "adj": 1, "adv": 1, "noun": 1, "verb": 1, "min_df": 1, "5": 1, "max_df": 1, "0": 1, "95": 1, "spacy_model": 1, "de_core_news_lg": 1, "n_doc": 1, "2000000": 1, "corpus_path": 1, "corpus_path_encod": 1, "latin1": 1, "load_clust": 1, "checkterm": 1, "politik": 1, "n_top_clust": 1, "3": 1, "cluster_shar": 1, "2": 1, "clustermethod": 1, "agglom": 1, "distance_threshold": 1, "n_word": 1, "40000": 1, "train_param": 1, "sourc": 1, "_basepredictor": 1, "properti": 1, "embedding_dim": 1, "dimension": 1, "vector": 1, "return": 1, "number": 1, "dimens": 1, "type": 1, "fit": 1, "x": 1, "seri": 1, "ndarrai": 1, "lex": 1, "support_lex": 1, "main_kei": 1, "iter": 1, "support_kei": 1, "hp_tune": 1, "n_iter": 1, "150": 1, "cv": 1, "param_grid": 1, "fixed_param": 1, "n_best_param": 1, "model": 1, "instanc": 1, "both": 1, "cluster": 1, "well": 1, "train": 1, "supervis": 1, "word": 1, "level": 1, "classif": 1, "paramet": 1, "union": 1, "pd": 1, "np": 1, "corpu": 1, "data": 1, "document": 1, "The": 1, "dictionari": 1, "i": 1, "us": 1, "option": 1, "addit": 1, "categori": 1, "These": 1, "among": 1, "predict": 1, "can": 1, "improv": 1, "perform": 1, "default": 1, "name": 1, "support": 1, "while": 1, "select": 1, "whether": 1, "hyperparamet": 1, "shall": 1, "tune": 1, "randomizedsearchcv": 1, "fold": 1, "cross": 1, "valid": 1, "grid": 1, "requir": 1, "all": 1, "best": 1, "aggreg": 1, "show": 1, "progress": 1, "bar": 1, "fit_ctfidf": 1, "method": 1, "given": 1, "fit_tfidf": 1, "fit_transform": 1, "y": 1, "fit_param": 1, "transform": 1, "version": 1, "arrai": 1, "like": 1, "shape": 1, "n_sampl": 1, "n_featur": 1, "input": 1, "sampl": 1, "n_output": 1, "target": 1, "valu": 1, "unsupervis": 1, "x_new": 1, "n_features_new": 1, "get_param": 1, "retriev": 1, "set": 1, "is_fit": 1, "tell": 1, "ha": 1, "been": 1, "alreadi": 1, "classmethod": 1, "load": 1, "path": 1, "previous": 1, "save": 1, "from": 1, "disk": 1, "locat": 1, "predict_doc": 1, "datafram": 1, "cutoff": 1, "n_batch": 1, "checkpoint_path": 1, "binari": 1, "probabl": 1, "If": 1, "run": 1, "batch": 1, "checkpoint": 1, "For": 1, "process": 1, "specifi": 1, "One": 1, "column": 1, "each": 1, "predict_proba_doc": 1, "rais": 1, "notfittederror": 1, "when": 1, "attempt": 1, "predict_proba_word": 1, "predict_word": 1, "compress": 1, "archiv": 1, "write": 1, "set_param": 1, "param": 1, "pass": 1, "keyword": 1, "exampl": 1, "dog": 1, "cat": 1, "1000": 1, "provid": 1, "ar": 1, "being": 1, "vocabulari": 1, "consid": 1, "embedding_dict": 1, "testvalu": 1, "test": 1, "object": 1, "lookup": 1, "dim": 1, "filter_term": 1, "term": 1, "tupl": 1, "filter": 1, "down": 1, "collect": 1, "e": 1, "includ": 1, "sinc": 1, "util": 1, "onli": 1, "fix": 1, "remov": 1, "unnecessari": 1, "ones": 1, "preserv": 1, "memori": 1, "reduc": 1, "kei": 1, "avail": 1, "load_filt": 1, "zipfil": 1, "zip": 1, "valueerror": 1, "load_vector": 1, "embedding_typ": 1, "fine_tun": 1, "instanti": 1, "pre": 1, "fasttext": 1, "word2vec": 1, "have": 1, "fine": 1, "matter": 1, "self": 1, "need": 1, "read": 1, "differ": 1, "than": 1, "offici": 1, "http": 1, "cc": 1, "an": 1, "invalid": 1, "enter": 1, "singl": 1, "multipl": 1, "size": 1, "inter": 1, "make_wv_from_keys_vector": 1, "creat": 1, "map": 1, "save_filt": 1, "where": 1, "befor": 1, "lexica": 1, "sep": 1, "encod": 1, "_baselexicon": 1, "regular": 1, "copi": 1, "dct": 1, "anim": 1, "food": 1, "bread": 1, "cake": 1, "mylex": 1, "mylex_copi": 1, "embedding_shap": 1, "matrix": 1, "get_vocabulari": 1, "sort": 1, "my_dct": 1, "salad": 1, "l": 1, "is_embed": 1, "look": 1, "up": 1, "directli": 1, "store": 1, "merg": 1, "inplac": 1, "one": 1, "more": 1, "other": 1, "thi": 1, "current": 1, "add": 1, "anoth": 1, "doe": 1, "allow": 1, "same": 1, "noth": 1, "new": 1, "With": [], "my_lex1": 1, "my_lex2": 1, "output": 1, "file": 1, "to_dict": 1, "format": 1, "A": 1, "b": 1, "c": 1, "d": 1, "pair": 1, "weightedlexicon": 1, "polar": 1, "score": 1, "my_lex": 1, "weight": 1, "numpi": 1, "merge_lexica": 1, "combin": 1, "my_dct1": 1, "my_dct2": 1, "combined_lex": 1, "latentsemanticsc": 1, "use_tfidf": 1, "scale_result": 1, "scaler": 1, "callabl": 1, "standard": 1, "doc_polar": 1, "doc": 1, "polarity_lexicon": 1, "panda": 1, "core": 1, "predict_vector": 1, "estim": 1, "work": 1, "simpl": 1, "nest": 1, "pipelin": 1, "latter": 1, "form": 1, "compon": 1, "__": 1, "so": 1, "": 1, "possibl": 1, "updat": 1, "stopwords_fil": 1, "build_analyz": 1, "call": 1, "tfidfvector": 1, "proprocess": 1, "thu": 1, "far": 1, "build_preprocessor": 1, "build_token": 1, "preprocess": 1, "check_fit": 1, "decod": 1, "fixed_vocabulary_": 1, "get_feature_nam": 1, "get_feature_names_out": 1, "input_featur": 1, "deep": 1, "get_stop_word": 1, "idf_": 1, "inverse_transform": 1, "zip_arch": 1, "stop_words_": 1, "vocabulary_": 1, "base": 1, "ensemble_cross_val_scor": [], "make_agg_sampl": [], "n": [], "draw": [], "randomli": [], "linear": [], "random": [], "ensur": [], "npdarraoth": [], "simplifi": [], "just": [], "integ": [], "take": [], "rel": [], "m": [], "observ": [], "_n_job": 1}, "objects": {"": [[1, 0, 0, "-", "weelex"]], "weelex": [[1, 0, 0, "-", "classifier"], [1, 0, 0, "-", "embeddings"], [1, 0, 0, "-", "lexicon"], [1, 0, 0, "-", "lsx"], [1, 0, 0, "-", "tfidf"]], "weelex.classifier": [[1, 1, 1, "", "WEELexClassifier"]], "weelex.classifier.WEELexClassifier": [[1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_ctfidf"], [1, 3, 1, "", "fit_tfidf"], [1, 3, 1, "", "fit_transform"], [1, 3, 1, "", "get_params"], [1, 2, 1, "", "is_fit"], [1, 3, 1, "", "load"], [1, 2, 1, "", "main_keys"], [1, 3, 1, "", "predict_docs"], [1, 3, 1, "", "predict_proba_docs"], [1, 3, 1, "", "predict_proba_words"], [1, 3, 1, "", "predict_words"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "support_keys"], [1, 2, 1, "", "vocabulary"]], "weelex.embeddings": [[1, 1, 1, "", "Embeddings"]], "weelex.embeddings.Embeddings": [[1, 2, 1, "", "dim"], [1, 3, 1, "", "filter_terms"], [1, 2, 1, "", "keys"], [1, 3, 1, "", "load_filtered"], [1, 3, 1, "", "load_vectors"], [1, 3, 1, "", "lookup"], [1, 3, 1, "", "make_wv_from_keys_vectors"], [1, 3, 1, "", "save_filtered"]], "weelex.lexicon": [[1, 1, 1, "", "Lexicon"], [1, 1, 1, "", "WeightedLexicon"], [1, 4, 1, "", "load"], [1, 4, 1, "", "merge_lexica"]], "weelex.lexicon.Lexicon": [[1, 3, 1, "", "copy"], [1, 3, 1, "", "embed"], [1, 2, 1, "", "embedding_shape"], [1, 2, 1, "", "embeddings"], [1, 3, 1, "", "get_vocabulary"], [1, 2, 1, "", "is_embedded"], [1, 2, 1, "", "keys"], [1, 3, 1, "", "load"], [1, 3, 1, "", "merge"], [1, 3, 1, "", "save"], [1, 3, 1, "", "to_dict"], [1, 2, 1, "", "vocabulary"]], "weelex.lexicon.WeightedLexicon": [[1, 3, 1, "", "copy"], [1, 3, 1, "", "embed"], [1, 2, 1, "", "embedding_shape"], [1, 2, 1, "", "embeddings"], [1, 3, 1, "", "get_vocabulary"], [1, 2, 1, "", "is_embedded"], [1, 2, 1, "", "keys"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 3, 1, "", "to_dict"], [1, 2, 1, "", "vocabulary"], [1, 2, 1, "", "weights"]], "weelex.lsx": [[1, 1, 1, "", "LatentSemanticScaling"]], "weelex.lsx.LatentSemanticScaling": [[1, 3, 1, "", "doc_polarity"], [1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_ctfidf"], [1, 3, 1, "", "fit_tfidf"], [1, 3, 1, "", "fit_transform"], [1, 3, 1, "", "get_params"], [1, 2, 1, "", "is_fit"], [1, 3, 1, "", "load"], [1, 3, 1, "", "polarity"], [1, 3, 1, "", "predict_docs"], [1, 3, 1, "", "predict_vectors"], [1, 3, 1, "", "predict_words"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "vocabulary"]], "weelex.tfidf": [[1, 1, 1, "", "BasicTfidf"]], "weelex.tfidf.BasicTfidf": [[1, 3, 1, "", "build_analyzer"], [1, 3, 1, "", "build_preprocessor"], [1, 3, 1, "", "build_tokenizer"], [1, 3, 1, "", "check_fit"], [1, 3, 1, "", "decode"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_transform"], [1, 2, 1, "", "fixed_vocabulary_"], [1, 3, 1, "", "get_feature_names"], [1, 3, 1, "", "get_feature_names_out"], [1, 3, 1, "", "get_params"], [1, 3, 1, "", "get_stop_words"], [1, 2, 1, "", "idf_"], [1, 3, 1, "", "inverse_transform"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "stop_words_"], [1, 3, 1, "", "transform"], [1, 2, 1, "", "vocabulary_"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "weelex": [0, 1], "": 0, "document": 0, "indic": 0, "tabl": 0, "packag": 1, "submodul": 1, "base": [], "modul": 1, "classifi": 1, "cli": [], "embed": 1, "ensembl": [], "lexicon": 1, "lsx": 1, "predictor": [], "tfidf": 1, "trainer": [], "content": 1, "_base": [], "_cli": [], "_ensembl": [], "_predictor": [], "_trainer": []}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Welcome to Weelex\u2019s documentation!": [[0, "welcome-to-weelex-s-documentation"]], "Indices and tables": [[0, "indices-and-tables"]], "weelex package": [[1, "weelex-package"]], "Submodules": [[1, "submodules"]], "weelex.classifier module": [[1, "module-weelex.classifier"]], "weelex.embeddings module": [[1, "module-weelex.embeddings"]], "weelex.lexicon module": [[1, "module-weelex.lexicon"]], "weelex.lsx module": [[1, "module-weelex.lsx"]], "weelex.tfidf module": [[1, "module-weelex.tfidf"]], "Module contents": [[1, "module-weelex"]]}, "indexentries": {"basictfidf (class in weelex.tfidf)": [[1, "weelex.tfidf.BasicTfidf"]], "embeddings (class in weelex.embeddings)": [[1, "weelex.embeddings.Embeddings"]], "latentsemanticscaling (class in weelex.lsx)": [[1, "weelex.lsx.LatentSemanticScaling"]], "lexicon (class in weelex.lexicon)": [[1, "weelex.lexicon.Lexicon"]], "weelexclassifier (class in weelex.classifier)": [[1, "weelex.classifier.WEELexClassifier"]], "weightedlexicon (class in weelex.lexicon)": [[1, "weelex.lexicon.WeightedLexicon"]], "build_analyzer() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.build_analyzer"]], "build_preprocessor() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.build_preprocessor"]], "build_tokenizer() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.build_tokenizer"]], "check_fit() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.check_fit"]], "copy() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.copy"]], "copy() (weelex.lexicon.weightedlexicon method)": [[1, "weelex.lexicon.WeightedLexicon.copy"]], "decode() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.decode"]], "dim (weelex.embeddings.embeddings property)": [[1, "weelex.embeddings.Embeddings.dim"]], "doc_polarity() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.doc_polarity"]], "embed() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.embed"]], "embed() (weelex.lexicon.weightedlexicon method)": [[1, "weelex.lexicon.WeightedLexicon.embed"]], "embedding_dim (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.embedding_dim"]], "embedding_dim (weelex.lsx.latentsemanticscaling property)": [[1, "weelex.lsx.LatentSemanticScaling.embedding_dim"]], "embedding_shape (weelex.lexicon.lexicon property)": [[1, "weelex.lexicon.Lexicon.embedding_shape"]], "embedding_shape (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.embedding_shape"]], "embeddings (weelex.lexicon.lexicon property)": [[1, "weelex.lexicon.Lexicon.embeddings"]], "embeddings (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.embeddings"]], "filter_terms() (weelex.embeddings.embeddings method)": [[1, "weelex.embeddings.Embeddings.filter_terms"]], "fit() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit"]], "fit() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.fit"]], "fit() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.fit"]], "fit_ctfidf() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_ctfidf"]], "fit_ctfidf() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.fit_ctfidf"]], "fit_tfidf() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_tfidf"]], "fit_tfidf() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.fit_tfidf"]], "fit_transform() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_transform"]], "fit_transform() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.fit_transform"]], "fit_transform() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.fit_transform"]], "fixed_vocabulary_ (weelex.tfidf.basictfidf property)": [[1, "weelex.tfidf.BasicTfidf.fixed_vocabulary_"]], "get_feature_names() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.get_feature_names"]], "get_feature_names_out() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.get_feature_names_out"]], "get_params() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.get_params"]], "get_params() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.get_params"]], "get_params() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.get_params"]], "get_stop_words() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.get_stop_words"]], "get_vocabulary() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.get_vocabulary"]], "get_vocabulary() (weelex.lexicon.weightedlexicon method)": [[1, "weelex.lexicon.WeightedLexicon.get_vocabulary"]], "idf_ (weelex.tfidf.basictfidf property)": [[1, "weelex.tfidf.BasicTfidf.idf_"]], "inverse_transform() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.inverse_transform"]], "is_embedded (weelex.lexicon.lexicon property)": [[1, "weelex.lexicon.Lexicon.is_embedded"]], "is_embedded (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.is_embedded"]], "is_fit (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.is_fit"]], "is_fit (weelex.lsx.latentsemanticscaling property)": [[1, "weelex.lsx.LatentSemanticScaling.is_fit"]], "keys (weelex.embeddings.embeddings property)": [[1, "weelex.embeddings.Embeddings.keys"]], "keys (weelex.lexicon.lexicon property)": [[1, "weelex.lexicon.Lexicon.keys"]], "keys (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.keys"]], "load() (in module weelex.lexicon)": [[1, "weelex.lexicon.load"]], "load() (weelex.classifier.weelexclassifier class method)": [[1, "weelex.classifier.WEELexClassifier.load"]], "load() (weelex.lexicon.lexicon class method)": [[1, "weelex.lexicon.Lexicon.load"]], "load() (weelex.lexicon.weightedlexicon class method)": [[1, "weelex.lexicon.WeightedLexicon.load"]], "load() (weelex.lsx.latentsemanticscaling class method)": [[1, "weelex.lsx.LatentSemanticScaling.load"]], "load() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.load"]], "load_filtered() (weelex.embeddings.embeddings class method)": [[1, "weelex.embeddings.Embeddings.load_filtered"]], "load_vectors() (weelex.embeddings.embeddings class method)": [[1, "weelex.embeddings.Embeddings.load_vectors"]], "lookup() (weelex.embeddings.embeddings method)": [[1, "weelex.embeddings.Embeddings.lookup"]], "main_keys (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.main_keys"]], "make_wv_from_keys_vectors() (weelex.embeddings.embeddings method)": [[1, "weelex.embeddings.Embeddings.make_wv_from_keys_vectors"]], "merge() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.merge"]], "merge_lexica() (in module weelex.lexicon)": [[1, "weelex.lexicon.merge_lexica"]], "module": [[1, "module-weelex"], [1, "module-weelex.classifier"], [1, "module-weelex.embeddings"], [1, "module-weelex.lexicon"], [1, "module-weelex.lsx"], [1, "module-weelex.tfidf"]], "polarity() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.polarity"]], "predict_docs() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_docs"]], "predict_docs() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.predict_docs"]], "predict_proba_docs() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_proba_docs"]], "predict_proba_words() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_proba_words"]], "predict_vectors() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.predict_vectors"]], "predict_words() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_words"]], "predict_words() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.predict_words"]], "save() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.save"]], "save() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.save"]], "save() (weelex.lexicon.weightedlexicon method)": [[1, "weelex.lexicon.WeightedLexicon.save"]], "save() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.save"]], "save() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.save"]], "save_filtered() (weelex.embeddings.embeddings method)": [[1, "weelex.embeddings.Embeddings.save_filtered"]], "set_params() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.set_params"]], "set_params() (weelex.lsx.latentsemanticscaling method)": [[1, "weelex.lsx.LatentSemanticScaling.set_params"]], "set_params() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.set_params"]], "stop_words_ (weelex.tfidf.basictfidf property)": [[1, "weelex.tfidf.BasicTfidf.stop_words_"]], "support_keys (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.support_keys"]], "to_dict() (weelex.lexicon.lexicon method)": [[1, "weelex.lexicon.Lexicon.to_dict"]], "to_dict() (weelex.lexicon.weightedlexicon method)": [[1, "weelex.lexicon.WeightedLexicon.to_dict"]], "transform() (weelex.tfidf.basictfidf method)": [[1, "weelex.tfidf.BasicTfidf.transform"]], "vocabulary (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.vocabulary"]], "vocabulary (weelex.lexicon.lexicon property)": [[1, "weelex.lexicon.Lexicon.vocabulary"]], "vocabulary (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.vocabulary"]], "vocabulary (weelex.lsx.latentsemanticscaling property)": [[1, "weelex.lsx.LatentSemanticScaling.vocabulary"]], "vocabulary_ (weelex.tfidf.basictfidf property)": [[1, "weelex.tfidf.BasicTfidf.vocabulary_"]], "weelex": [[1, "module-weelex"]], "weelex.classifier": [[1, "module-weelex.classifier"]], "weelex.embeddings": [[1, "module-weelex.embeddings"]], "weelex.lexicon": [[1, "module-weelex.lexicon"]], "weelex.lsx": [[1, "module-weelex.lsx"]], "weelex.tfidf": [[1, "module-weelex.tfidf"]], "weights (weelex.lexicon.weightedlexicon property)": [[1, "weelex.lexicon.WeightedLexicon.weights"]]}})