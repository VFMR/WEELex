Search.setIndex({"docnames": ["index", "modules/classifier", "modules/embeddings", "modules/index", "modules/lexicon", "modules/lsx", "modules/tfidf", "weelex"], "filenames": ["index.rst", "modules\\classifier.rst", "modules\\embeddings.rst", "modules\\index.rst", "modules\\lexicon.rst", "modules\\lsx.rst", "modules\\tfidf.rst", "weelex.rst"], "titles": ["Welcome to Weelex\u2019s documentation!", "classifier module", "embeddings module", "&lt;no title&gt;", "weelex.lexicon module", "lsx module", "weelex.tfidf module", "weelex package"], "terms": {"index": 0, "modul": 0, "search": 0, "page": 0, "contain": [1, 2, 4], "main": 1, "class": [1, 2, 4, 5, 6], "weelexclassifi": 1, "emb": [1, 2, 4, 5], "dict": [1, 2, 4, 5], "str": [1, 2, 4, 5, 6], "basictfidf": [1, 5, 6], "none": [1, 2, 4, 5, 6], "ctfidf": [1, 5], "clustertfidfvector": [1, 5], "use_ctfidf": [1, 5], "bool": [1, 2, 4, 5], "true": [1, 4, 5, 6], "word_level_aggreg": [1, 5], "test_siz": 1, "float": [1, 2, 4, 5], "random_st": [1, 5], "int": [1, 2, 4, 5], "n_job": [1, 5], "1": [1, 4, 5], "progress_bar": [1, 5], "fals": [1, 2, 4, 5], "relevant_po": [1, 5, 6], "list": [1, 2, 4, 5], "adj": [1, 5, 6], "adv": [1, 5, 6], "noun": [1, 5, 6], "verb": [1, 5, 6], "min_df": [1, 5, 6], "5": [1, 5, 6], "max_df": [1, 5, 6], "0": [1, 4, 5, 6], "95": [1, 5, 6], "spacy_model": [1, 5, 6], "de_core_news_lg": [1, 5, 6], "n_doc": [1, 5], "2000000": [1, 5], "corpus_path": [1, 5], "corpus_path_encod": [1, 5], "latin1": [1, 5], "load_clust": [1, 5], "checkterm": [1, 5], "politik": [1, 5], "n_top_clust": [1, 5], "3": [1, 5], "cluster_shar": [1, 5], "2": [1, 4, 5], "clustermethod": [1, 5], "agglom": [1, 5], "distance_threshold": [1, 5], "n_word": [1, 5], "40000": [1, 5], "train_param": 1, "sourc": [1, 2, 4, 5, 6], "base": [1, 2, 4, 5, 6], "_basepredictor": [1, 5], "properti": [1, 2, 4, 5, 6], "embedding_dim": [1, 5], "dimension": [1, 2, 5], "vector": [1, 2, 4, 5], "return": [1, 2, 4, 5], "number": [1, 2, 5], "dimens": [1, 5], "type": [1, 2, 4, 5], "fit": [1, 5, 6], "x": [1, 5, 6], "seri": [1, 2, 5], "ndarrai": [1, 2, 4, 5], "lex": 1, "support_lex": 1, "main_kei": 1, "iter": [1, 2, 4], "support_kei": 1, "hp_tune": 1, "n_iter": 1, "150": 1, "cv": 1, "param_grid": 1, "fixed_param": 1, "n_best_param": 1, "model": [1, 2, 5], "instanc": [1, 2, 4, 5], "both": 1, "cluster": [1, 5], "well": [1, 5], "train": [1, 2, 5], "supervis": 1, "word": [1, 2, 4, 5], "level": 1, "classif": 1, "paramet": [1, 2, 4, 5], "union": [1, 2, 4, 5], "pd": [1, 2, 4, 5], "np": [1, 2, 5], "corpu": [1, 5], "data": [1, 5], "document": [1, 5], "The": [1, 2, 4, 5], "dictionari": [1, 4], "i": [1, 2, 4, 5], "us": 1, "option": [1, 2, 4, 5], "addit": [1, 5], "categori": [1, 4], "These": 1, "among": 1, "predict": 1, "can": [1, 4], "improv": 1, "perform": 1, "default": [1, 2, 4, 5], "name": [1, 2], "support": [1, 2, 4], "while": 1, "select": 1, "whether": [1, 2, 4, 5], "hyperparamet": 1, "shall": [1, 4], "tune": [1, 2], "randomizedsearchcv": 1, "fold": 1, "cross": 1, "valid": 1, "grid": 1, "requir": [1, 2], "all": [1, 4], "best": 1, "aggreg": 1, "show": 1, "progress": 1, "bar": 1, "fit_ctfidf": [1, 5], "method": [1, 2, 5, 6], "given": [1, 5], "fit_tfidf": [1, 5], "fit_transform": [1, 5, 6], "y": [1, 5, 6], "fit_param": [1, 5], "transform": [1, 5, 6], "version": [1, 5], "arrai": [1, 2, 4, 5], "like": [1, 5], "shape": [1, 4, 5], "n_sampl": [1, 5], "n_featur": [1, 5], "input": [1, 5], "sampl": [1, 5], "n_output": [1, 5], "target": [1, 5], "valu": [1, 4, 5], "unsupervis": [1, 5], "x_new": [1, 5], "n_features_new": [1, 5], "get_param": [1, 5, 6], "deep": [1, 5, 6], "retriev": [1, 2, 4, 5], "set": [1, 5], "is_fit": [1, 5], "tell": [1, 4, 5], "ha": [1, 2, 5], "been": [1, 2, 4, 5], "alreadi": [1, 5], "classmethod": [1, 2, 4, 5], "load": [1, 2, 4, 5, 6], "path": [1, 2, 4, 5, 6], "previous": [1, 2, 4, 5], "save": [1, 2, 4, 5, 6], "from": [1, 2, 4, 5], "disk": [1, 2, 4, 5], "locat": [1, 2, 5], "predict_doc": [1, 5], "datafram": [1, 2, 4], "cutoff": 1, "n_batch": [1, 5], "checkpoint_path": [1, 5], "binari": 1, "probabl": 1, "If": [1, 2, 4], "run": 1, "batch": 1, "checkpoint": 1, "For": 1, "process": 1, "specifi": 1, "One": [1, 2], "column": 1, "each": [1, 4, 5], "predict_proba_doc": 1, "rais": [1, 2], "notfittederror": 1, "when": [1, 2], "attempt": 1, "predict_proba_word": 1, "predict_word": [1, 5], "compress": [1, 5], "archiv": [1, 2, 4, 5], "write": [1, 5], "set_param": [1, 5, 6], "param": [1, 5, 6], "pass": [1, 4], "keyword": 1, "exampl": [1, 2, 4], "dog": [1, 4], "cat": [1, 4], "_n_job": 1, "1000": 1, "provid": [1, 2], "ar": [1, 2, 4, 5], "being": 1, "vocabulari": [1, 2, 4, 5], "consid": [1, 5], "embedding_dict": 2, "testvalu": 2, "test": 2, "object": [2, 4, 5, 6], "lookup": 2, "dim": 2, "filter_term": 2, "term": 2, "tupl": [2, 4], "filter": 2, "down": 2, "collect": 2, "e": 2, "includ": [2, 4, 6], "sinc": 2, "util": 2, "onli": [2, 4], "fix": 2, "remov": 2, "unnecessari": 2, "ones": 2, "preserv": 2, "memori": 2, "reduc": 2, "kei": [2, 4], "avail": 2, "load_filt": 2, "zipfil": [2, 4, 6], "zip": [2, 4], "valueerror": 2, "load_vector": 2, "embedding_typ": 2, "fine_tun": 2, "instanti": 2, "pre": 2, "fasttext": 2, "word2vec": 2, "have": [2, 4, 5], "fine": 2, "matter": 2, "self": [2, 5], "need": 2, "read": 2, "differ": [2, 4], "than": 2, "offici": 2, "http": 2, "cc": 2, "an": 2, "invalid": 2, "enter": 2, "singl": 2, "multipl": [2, 4], "size": 2, "inter": 2, "make_wv_from_keys_vector": 2, "creat": 2, "map": [2, 4], "save_filt": 2, "where": 2, "befor": 2, "lexica": 4, "sep": 4, "encod": 4, "_baselexicon": 4, "regular": 4, "copi": 4, "dct": 4, "anim": 4, "food": 4, "bread": 4, "cake": 4, "mylex": 4, "mylex_copi": 4, "embedding_shap": 4, "matrix": 4, "get_vocabulari": 4, "sort": 4, "my_dct": 4, "salad": 4, "l": 4, "is_embed": 4, "look": 4, "up": 4, "directli": 4, "store": 4, "merg": 4, "inplac": 4, "one": 4, "more": 4, "other": 4, "thi": [4, 5], "current": 4, "add": 4, "anoth": 4, "doe": [4, 6], "allow": 4, "same": 4, "noth": 4, "new": 4, "my_lex1": 4, "my_lex2": 4, "output": 4, "file": 4, "to_dict": 4, "format": 4, "A": 4, "b": 4, "c": 4, "d": 4, "pair": 4, "weightedlexicon": [4, 5], "polar": [4, 5], "score": 4, "my_lex": 4, "weight": 4, "numpi": [4, 5], "merge_lexica": 4, "combin": 4, "my_dct1": 4, "my_dct2": 4, "combined_lex": 4, "latentsemanticsc": 5, "use_tfidf": 5, "scale_result": 5, "scaler": 5, "callabl": 5, "standard": 5, "doc_polar": 5, "doc": [5, 6], "polarity_lexicon": 5, "panda": 5, "core": 5, "predict_vector": 5, "estim": 5, "work": 5, "simpl": 5, "nest": 5, "pipelin": 5, "latter": 5, "form": 5, "compon": 5, "__": 5, "so": 5, "": 5, "possibl": 5, "updat": 5, "stopwords_fil": 6, "build_analyz": 6, "call": 6, "tfidfvector": 6, "proprocess": 6, "thu": 6, "far": 6, "build_preprocessor": 6, "build_token": 6, "preprocess": 6, "check_fit": 6, "decod": 6, "fixed_vocabulary_": 6, "get_feature_nam": 6, "get_feature_names_out": 6, "input_featur": 6, "get_stop_word": 6, "idf_": 6, "inverse_transform": 6, "zip_arch": 6, "stop_words_": 6, "vocabulary_": 6, "embed": [1, 4, 5], "tfidf": [1, 5], "lexicon": [1, 2], "weelex": [1, 2, 5]}, "objects": {"": [[7, 0, 0, "-", "weelex"]], "weelex": [[1, 0, 0, "-", "classifier"], [2, 0, 0, "-", "embeddings"], [4, 0, 0, "-", "lexicon"], [5, 0, 0, "-", "lsx"], [6, 0, 0, "-", "tfidf"]], "weelex.classifier": [[1, 1, 1, "", "WEELexClassifier"]], "weelex.classifier.WEELexClassifier": [[1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_ctfidf"], [1, 3, 1, "", "fit_tfidf"], [1, 3, 1, "", "fit_transform"], [1, 3, 1, "", "get_params"], [1, 2, 1, "", "is_fit"], [1, 3, 1, "", "load"], [1, 2, 1, "", "main_keys"], [1, 3, 1, "", "predict_docs"], [1, 3, 1, "", "predict_proba_docs"], [1, 3, 1, "", "predict_proba_words"], [1, 3, 1, "", "predict_words"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "support_keys"], [1, 2, 1, "", "vocabulary"]], "weelex.embeddings": [[2, 1, 1, "", "Embeddings"]], "weelex.embeddings.Embeddings": [[2, 2, 1, "", "dim"], [2, 3, 1, "", "filter_terms"], [2, 2, 1, "", "keys"], [2, 3, 1, "", "load_filtered"], [2, 3, 1, "", "load_vectors"], [2, 3, 1, "", "lookup"], [2, 3, 1, "", "make_wv_from_keys_vectors"], [2, 3, 1, "", "save_filtered"]], "weelex.lexicon": [[4, 1, 1, "", "Lexicon"], [4, 1, 1, "", "WeightedLexicon"], [4, 4, 1, "", "load"], [4, 4, 1, "", "merge_lexica"]], "weelex.lexicon.Lexicon": [[4, 3, 1, "", "copy"], [4, 3, 1, "", "embed"], [4, 2, 1, "", "embedding_shape"], [4, 2, 1, "", "embeddings"], [4, 3, 1, "", "get_vocabulary"], [4, 2, 1, "", "is_embedded"], [4, 2, 1, "", "keys"], [4, 3, 1, "", "load"], [4, 3, 1, "", "merge"], [4, 3, 1, "", "save"], [4, 3, 1, "", "to_dict"], [4, 2, 1, "", "vocabulary"]], "weelex.lexicon.WeightedLexicon": [[4, 3, 1, "", "copy"], [4, 3, 1, "", "embed"], [4, 2, 1, "", "embedding_shape"], [4, 2, 1, "", "embeddings"], [4, 3, 1, "", "get_vocabulary"], [4, 2, 1, "", "is_embedded"], [4, 2, 1, "", "keys"], [4, 3, 1, "", "load"], [4, 3, 1, "", "save"], [4, 3, 1, "", "to_dict"], [4, 2, 1, "", "vocabulary"], [4, 2, 1, "", "weights"]], "weelex.lsx": [[5, 1, 1, "", "LatentSemanticScaling"]], "weelex.lsx.LatentSemanticScaling": [[5, 3, 1, "", "doc_polarity"], [5, 2, 1, "", "embedding_dim"], [5, 3, 1, "", "fit"], [5, 3, 1, "", "fit_ctfidf"], [5, 3, 1, "", "fit_tfidf"], [5, 3, 1, "", "fit_transform"], [5, 3, 1, "", "get_params"], [5, 2, 1, "", "is_fit"], [5, 3, 1, "", "load"], [5, 3, 1, "", "polarity"], [5, 3, 1, "", "predict_docs"], [5, 3, 1, "", "predict_vectors"], [5, 3, 1, "", "predict_words"], [5, 3, 1, "", "save"], [5, 3, 1, "", "set_params"], [5, 2, 1, "", "vocabulary"]], "weelex.tfidf": [[6, 1, 1, "", "BasicTfidf"]], "weelex.tfidf.BasicTfidf": [[6, 3, 1, "", "build_analyzer"], [6, 3, 1, "", "build_preprocessor"], [6, 3, 1, "", "build_tokenizer"], [6, 3, 1, "", "check_fit"], [6, 3, 1, "", "decode"], [6, 3, 1, "", "fit"], [6, 3, 1, "", "fit_transform"], [6, 2, 1, "", "fixed_vocabulary_"], [6, 3, 1, "", "get_feature_names"], [6, 3, 1, "", "get_feature_names_out"], [6, 3, 1, "", "get_params"], [6, 3, 1, "", "get_stop_words"], [6, 2, 1, "", "idf_"], [6, 3, 1, "", "inverse_transform"], [6, 3, 1, "", "load"], [6, 3, 1, "", "save"], [6, 3, 1, "", "set_params"], [6, 2, 1, "", "stop_words_"], [6, 3, 1, "", "transform"], [6, 2, 1, "", "vocabulary_"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "weelex": [0, 4, 6, 7], "": 0, "document": 0, "indic": 0, "tabl": 0, "packag": 7, "submodul": [], "classifi": 1, "modul": [1, 2, 4, 5, 6, 7], "embed": 2, "lexicon": 4, "lsx": 5, "tfidf": 6, "content": 7}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Welcome to Weelex\u2019s documentation!": [[0, "welcome-to-weelex-s-documentation"]], "Indices and tables": [[0, "indices-and-tables"]], "classifier module": [[1, "module-weelex.classifier"]], "embeddings module": [[2, "module-weelex.embeddings"]], "weelex.lexicon module": [[4, "module-weelex.lexicon"]], "lsx module": [[5, "module-weelex.lsx"]], "weelex.tfidf module": [[6, "module-weelex.tfidf"]], "weelex package": [[7, "weelex-package"]], "Module contents": [[7, "module-weelex"]]}, "indexentries": {"weelexclassifier (class in weelex.classifier)": [[1, "weelex.classifier.WEELexClassifier"]], "embedding_dim (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.embedding_dim"]], "fit() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit"]], "fit_ctfidf() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_ctfidf"]], "fit_tfidf() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_tfidf"]], "fit_transform() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.fit_transform"]], "get_params() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.get_params"]], "is_fit (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.is_fit"]], "load() (weelex.classifier.weelexclassifier class method)": [[1, "weelex.classifier.WEELexClassifier.load"]], "main_keys (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.main_keys"]], "module": [[1, "module-weelex.classifier"], [2, "module-weelex.embeddings"], [4, "module-weelex.lexicon"], [5, "module-weelex.lsx"], [6, "module-weelex.tfidf"], [7, "module-weelex"]], "predict_docs() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_docs"]], "predict_proba_docs() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_proba_docs"]], "predict_proba_words() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_proba_words"]], "predict_words() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.predict_words"]], "save() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.save"]], "set_params() (weelex.classifier.weelexclassifier method)": [[1, "weelex.classifier.WEELexClassifier.set_params"]], "support_keys (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.support_keys"]], "vocabulary (weelex.classifier.weelexclassifier property)": [[1, "weelex.classifier.WEELexClassifier.vocabulary"]], "weelex.classifier": [[1, "module-weelex.classifier"]], "embeddings (class in weelex.embeddings)": [[2, "weelex.embeddings.Embeddings"]], "dim (weelex.embeddings.embeddings property)": [[2, "weelex.embeddings.Embeddings.dim"]], "filter_terms() (weelex.embeddings.embeddings method)": [[2, "weelex.embeddings.Embeddings.filter_terms"]], "keys (weelex.embeddings.embeddings property)": [[2, "weelex.embeddings.Embeddings.keys"]], "load_filtered() (weelex.embeddings.embeddings class method)": [[2, "weelex.embeddings.Embeddings.load_filtered"]], "load_vectors() (weelex.embeddings.embeddings class method)": [[2, "weelex.embeddings.Embeddings.load_vectors"]], "lookup() (weelex.embeddings.embeddings method)": [[2, "weelex.embeddings.Embeddings.lookup"]], "make_wv_from_keys_vectors() (weelex.embeddings.embeddings method)": [[2, "weelex.embeddings.Embeddings.make_wv_from_keys_vectors"]], "save_filtered() (weelex.embeddings.embeddings method)": [[2, "weelex.embeddings.Embeddings.save_filtered"]], "weelex.embeddings": [[2, "module-weelex.embeddings"]], "lexicon (class in weelex.lexicon)": [[4, "weelex.lexicon.Lexicon"]], "weightedlexicon (class in weelex.lexicon)": [[4, "weelex.lexicon.WeightedLexicon"]], "copy() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.copy"]], "copy() (weelex.lexicon.weightedlexicon method)": [[4, "weelex.lexicon.WeightedLexicon.copy"]], "embed() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.embed"]], "embed() (weelex.lexicon.weightedlexicon method)": [[4, "weelex.lexicon.WeightedLexicon.embed"]], "embedding_shape (weelex.lexicon.lexicon property)": [[4, "weelex.lexicon.Lexicon.embedding_shape"]], "embedding_shape (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.embedding_shape"]], "embeddings (weelex.lexicon.lexicon property)": [[4, "weelex.lexicon.Lexicon.embeddings"]], "embeddings (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.embeddings"]], "get_vocabulary() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.get_vocabulary"]], "get_vocabulary() (weelex.lexicon.weightedlexicon method)": [[4, "weelex.lexicon.WeightedLexicon.get_vocabulary"]], "is_embedded (weelex.lexicon.lexicon property)": [[4, "weelex.lexicon.Lexicon.is_embedded"]], "is_embedded (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.is_embedded"]], "keys (weelex.lexicon.lexicon property)": [[4, "weelex.lexicon.Lexicon.keys"]], "keys (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.keys"]], "load() (in module weelex.lexicon)": [[4, "weelex.lexicon.load"]], "load() (weelex.lexicon.lexicon class method)": [[4, "weelex.lexicon.Lexicon.load"]], "load() (weelex.lexicon.weightedlexicon class method)": [[4, "weelex.lexicon.WeightedLexicon.load"]], "merge() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.merge"]], "merge_lexica() (in module weelex.lexicon)": [[4, "weelex.lexicon.merge_lexica"]], "save() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.save"]], "save() (weelex.lexicon.weightedlexicon method)": [[4, "weelex.lexicon.WeightedLexicon.save"]], "to_dict() (weelex.lexicon.lexicon method)": [[4, "weelex.lexicon.Lexicon.to_dict"]], "to_dict() (weelex.lexicon.weightedlexicon method)": [[4, "weelex.lexicon.WeightedLexicon.to_dict"]], "vocabulary (weelex.lexicon.lexicon property)": [[4, "weelex.lexicon.Lexicon.vocabulary"]], "vocabulary (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.vocabulary"]], "weelex.lexicon": [[4, "module-weelex.lexicon"]], "weights (weelex.lexicon.weightedlexicon property)": [[4, "weelex.lexicon.WeightedLexicon.weights"]], "latentsemanticscaling (class in weelex.lsx)": [[5, "weelex.lsx.LatentSemanticScaling"]], "doc_polarity() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.doc_polarity"]], "embedding_dim (weelex.lsx.latentsemanticscaling property)": [[5, "weelex.lsx.LatentSemanticScaling.embedding_dim"]], "fit() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.fit"]], "fit_ctfidf() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.fit_ctfidf"]], "fit_tfidf() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.fit_tfidf"]], "fit_transform() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.fit_transform"]], "get_params() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.get_params"]], "is_fit (weelex.lsx.latentsemanticscaling property)": [[5, "weelex.lsx.LatentSemanticScaling.is_fit"]], "load() (weelex.lsx.latentsemanticscaling class method)": [[5, "weelex.lsx.LatentSemanticScaling.load"]], "polarity() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.polarity"]], "predict_docs() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.predict_docs"]], "predict_vectors() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.predict_vectors"]], "predict_words() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.predict_words"]], "save() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.save"]], "set_params() (weelex.lsx.latentsemanticscaling method)": [[5, "weelex.lsx.LatentSemanticScaling.set_params"]], "vocabulary (weelex.lsx.latentsemanticscaling property)": [[5, "weelex.lsx.LatentSemanticScaling.vocabulary"]], "weelex.lsx": [[5, "module-weelex.lsx"]], "basictfidf (class in weelex.tfidf)": [[6, "weelex.tfidf.BasicTfidf"]], "build_analyzer() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.build_analyzer"]], "build_preprocessor() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.build_preprocessor"]], "build_tokenizer() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.build_tokenizer"]], "check_fit() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.check_fit"]], "decode() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.decode"]], "fit() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.fit"]], "fit_transform() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.fit_transform"]], "fixed_vocabulary_ (weelex.tfidf.basictfidf property)": [[6, "weelex.tfidf.BasicTfidf.fixed_vocabulary_"]], "get_feature_names() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.get_feature_names"]], "get_feature_names_out() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.get_feature_names_out"]], "get_params() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.get_params"]], "get_stop_words() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.get_stop_words"]], "idf_ (weelex.tfidf.basictfidf property)": [[6, "weelex.tfidf.BasicTfidf.idf_"]], "inverse_transform() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.inverse_transform"]], "load() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.load"]], "save() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.save"]], "set_params() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.set_params"]], "stop_words_ (weelex.tfidf.basictfidf property)": [[6, "weelex.tfidf.BasicTfidf.stop_words_"]], "transform() (weelex.tfidf.basictfidf method)": [[6, "weelex.tfidf.BasicTfidf.transform"]], "vocabulary_ (weelex.tfidf.basictfidf property)": [[6, "weelex.tfidf.BasicTfidf.vocabulary_"]], "weelex.tfidf": [[6, "module-weelex.tfidf"]], "weelex": [[7, "module-weelex"]]}})