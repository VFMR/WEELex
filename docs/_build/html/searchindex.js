Search.setIndex({"docnames": ["index", "modules", "weelex"], "filenames": ["index.rst", "modules.rst", "weelex.rst"], "titles": ["Welcome to Weelex\u2019s documentation!", "weelex", "weelex package"], "terms": {"index": 0, "modul": [0, 1], "search": 0, "page": 0, "packag": 1, "submodul": 1, "base": 1, "classifi": 1, "cli": 1, "embed": 1, "ensembl": 1, "lexicon": 1, "lsx": 1, "predictor": 1, "tfidf": 1, "trainer": 1, "content": 1, "class": 2, "embedding_dict": 2, "option": 2, "dict": 2, "str": 2, "float": 2, "none": 2, "testvalu": 2, "test": 2, "sourc": 2, "object": 2, "properti": 2, "dim": 2, "filter_term": 2, "term": 2, "union": 2, "list": 2, "ndarrai": 2, "datafram": 2, "tupl": 2, "kei": 2, "classmethod": 2, "load_facebook_vector": 2, "path": 2, "load_filt": 2, "archiv": 2, "zipfil": 2, "load_finetuned_fasttext": 2, "load_finetuned_word2vec": 2, "load_vector": 2, "embedding_typ": 2, "fine_tun": 2, "bool": 2, "fals": 2, "lookup": 2, "seri": 2, "make_wv_from_keys_vector": 2, "save_filt": 2, "augmentedensembl": 2, "categori": 2, "outside_categori": 2, "n_model": 2, "10": 2, "n_samples_multipli": 2, "5": 2, "n_samples_multiplier_outsid": 2, "input_shap": 2, "300": 2, "modeltyp": 2, "svm": 2, "pca": 2, "svc_c": 2, "1": 2, "0": 2, "svc_kernel": 2, "rbf": 2, "progress_bar": 2, "n_vectors_agg_train": 2, "3": 2, "run_fast": 2, "random_st": 2, "modelkwarg": 2, "baseensembl": 2, "baseestim": 2, "train": 2, "an": 2, "model": 2, "For": 2, "each": 2, "random": 2, "select": 2, "input": 2, "vector": 2, "aggreg": 2, "linear": 2, "combin": 2, "augment": 2, "data": 2, "paramet": 2, "sklearn": 2, "estim": 2, "draw_random_samples_classwis": 2, "x": 2, "y": 2, "classvalu": 2, "int": 2, "n_sampl": 2, "include_all_origin": 2, "true": 2, "word": 2, "randomli": 2, "specif": 2, "make": 2, "panda": 2, "The": 2, "matrix": 2, "contain": 2, "valu": 2, "current": 2, "consid": 2, "multipli": 2, "number": 2, "origin": 2, "get": 2, "observ": 2, "shall": 2, "drawn": 2, "sampl": 2, "default": 2, "whether": 2, "i": 2, "e": 2, "non": 2, "includ": 2, "return": 2, "arrai": 2, "can": 2, "us": 2, "machin": 2, "learn": 2, "type": 2, "numpi": 2, "fit": 2, "method": 2, "ml": 2, "via": 2, "pass": 2, "binari": 2, "tell": 2, "belong": 2, "insid": 2, "part": 2, "predict": 2, "outsid": 2, "from": 2, "differ": 2, "one": 2, "A": 2, "form": 2, "target": 2, "load": 2, "filenam": 2, "hyper": 2, "were": 2, "save": 2, "name": 2, "file": 2, "cutoff": 2, "predict_proba": 2, "like": 2, "probabl": 2, "mean": 2, "probabilit": 2, "individu": 2, "disk": 2, "thi": 2, "later": 2, "score": 2, "score_func": 2, "function": 2, "f1_score": 2, "tune": 2, "callabl": 2, "metric": 2, "fullensembl": 2, "param_set": 2, "modelparam": 2, "ensemble_cross_val_scor": 2, "cv": 2, "make_agg_sampl": 2, "n": 2, "draw": 2, "weight": 2, "ensur": 2, "npdarraoth": 2, "add": 2, "up": 2, "simplifi": 2, "just": 2, "integ": 2, "take": 2, "rel": 2, "size": 2, "m": 2, "shape": 2, "onli": 2, "baselexicon": 2, "dictionari": 2, "core": 2, "frame": 2, "sep": 2, "encod": 2, "copi": 2, "emb": 2, "embedding_shap": 2, "get_vocabulari": 2, "sort": 2, "all": 2, "exampl": 2, "my_dct": 2, "food": 2, "bread": 2, "salad": 2, "anim": 2, "dog": 2, "cat": 2, "l": 2, "is_embed": 2, "previous": 2, "instanc": 2, "output": 2, "to_dict": 2, "format": 2, "b": 2, "c": 2, "d": 2, "pair": 2, "vocabulari": 2, "merg": 2, "lexica": 2, "iter": 2, "inplac": 2, "weightedlexicon": 2, "merge_lexica": 2, "basictfidf": 2, "stopwords_fil": 2, "relevant_po": 2, "adj": 2, "adv": 2, "noun": 2, "verb": 2, "min_df": 2, "max_df": 2, "95": 2, "spacy_model": 2, "de_core_news_lg": 2, "build_analyz": 2, "call": 2, "tfidfvector": 2, "doe": 2, "proprocess": 2, "thu": 2, "far": 2, "build_preprocessor": 2, "build_token": 2, "preprocess": 2, "check_fit": 2, "decod": 2, "doc": 2, "fit_transform": 2, "fixed_vocabulary_": 2, "get_feature_nam": 2, "get_feature_names_out": 2, "input_featur": 2, "get_param": 2, "deep": 2, "get_stop_word": 2, "idf_": 2, "inverse_transform": 2, "zip_arch": 2, "set_param": 2, "param": 2, "stop_words_": 2, "transform": 2, "vocabulary_": 2, "tfidfclean": 2, "transformermixin": 2, "static": 2, "remove_url": 2, "text": 2, "remov": 2, "url": 2, "found": 2, "string": 2, "regular": 2, "express": 2, "tfidf_cleanup": 2}, "objects": {"weelex": [[2, 0, 0, "-", "embeddings"], [2, 0, 0, "-", "ensemble"], [2, 0, 0, "-", "lexicon"], [2, 0, 0, "-", "tfidf"]], "weelex.embeddings": [[2, 1, 1, "", "Embeddings"]], "weelex.embeddings.Embeddings": [[2, 2, 1, "", "dim"], [2, 3, 1, "", "filter_terms"], [2, 2, 1, "", "keys"], [2, 3, 1, "", "load_facebook_vectors"], [2, 3, 1, "", "load_filtered"], [2, 3, 1, "", "load_finetuned_fasttext"], [2, 3, 1, "", "load_finetuned_word2vec"], [2, 3, 1, "", "load_vectors"], [2, 3, 1, "", "lookup"], [2, 3, 1, "", "make_wv_from_keys_vectors"], [2, 3, 1, "", "save_filtered"]], "weelex.ensemble": [[2, 1, 1, "", "AugmentedEnsemble"], [2, 1, 1, "", "BaseEnsemble"], [2, 1, 1, "", "FullEnsemble"], [2, 4, 1, "", "ensemble_cross_val_score"], [2, 4, 1, "", "make_agg_sample"]], "weelex.ensemble.AugmentedEnsemble": [[2, 3, 1, "", "draw_random_samples_classwise"], [2, 3, 1, "", "fit"], [2, 3, 1, "", "load"], [2, 3, 1, "", "predict"], [2, 3, 1, "", "predict_proba"], [2, 3, 1, "", "save"], [2, 3, 1, "", "score"]], "weelex.ensemble.FullEnsemble": [[2, 3, 1, "", "fit"], [2, 3, 1, "", "load"], [2, 3, 1, "", "predict"], [2, 3, 1, "", "predict_proba"], [2, 3, 1, "", "save"]], "weelex.lexicon": [[2, 1, 1, "", "BaseLexicon"], [2, 1, 1, "", "Lexicon"], [2, 1, 1, "", "WeightedLexicon"], [2, 4, 1, "", "load"], [2, 4, 1, "", "merge_lexica"]], "weelex.lexicon.BaseLexicon": [[2, 3, 1, "", "copy"], [2, 3, 1, "", "embed"], [2, 2, 1, "", "embedding_shape"], [2, 2, 1, "", "embeddings"], [2, 3, 1, "", "get_vocabulary"], [2, 2, 1, "", "is_embedded"], [2, 2, 1, "", "keys"], [2, 3, 1, "", "load"], [2, 3, 1, "", "save"], [2, 3, 1, "", "to_dict"], [2, 2, 1, "", "vocabulary"]], "weelex.lexicon.Lexicon": [[2, 3, 1, "", "merge"]], "weelex.lexicon.WeightedLexicon": [[2, 3, 1, "", "embed"], [2, 3, 1, "", "load"], [2, 3, 1, "", "save"], [2, 3, 1, "", "to_dict"], [2, 2, 1, "", "vocabulary"], [2, 2, 1, "", "weights"]], "weelex.tfidf": [[2, 1, 1, "", "BasicTfidf"], [2, 1, 1, "", "TfidfCleaner"], [2, 4, 1, "", "remove_urls"], [2, 4, 1, "", "tfidf_cleanup"]], "weelex.tfidf.BasicTfidf": [[2, 3, 1, "", "build_analyzer"], [2, 3, 1, "", "build_preprocessor"], [2, 3, 1, "", "build_tokenizer"], [2, 3, 1, "", "check_fit"], [2, 3, 1, "", "decode"], [2, 3, 1, "", "fit"], [2, 3, 1, "", "fit_transform"], [2, 2, 1, "", "fixed_vocabulary_"], [2, 3, 1, "", "get_feature_names"], [2, 3, 1, "", "get_feature_names_out"], [2, 3, 1, "", "get_params"], [2, 3, 1, "", "get_stop_words"], [2, 2, 1, "", "idf_"], [2, 3, 1, "", "inverse_transform"], [2, 3, 1, "", "load"], [2, 3, 1, "", "save"], [2, 3, 1, "", "set_params"], [2, 2, 1, "", "stop_words_"], [2, 3, 1, "", "transform"], [2, 2, 1, "", "vocabulary_"]], "weelex.tfidf.TfidfCleaner": [[2, 3, 1, "", "fit"], [2, 3, 1, "", "transform"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "weelex": [0, 1, 2], "s": 0, "document": 0, "indic": 0, "tabl": 0, "packag": 2, "submodul": 2, "base": 2, "modul": 2, "classifi": 2, "cli": 2, "embed": 2, "ensembl": 2, "lexicon": 2, "lsx": 2, "predictor": 2, "tfidf": 2, "trainer": 2, "content": 2}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})