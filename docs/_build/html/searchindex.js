Search.setIndex({"docnames": ["index", "weelex"], "filenames": ["index.rst", "weelex.rst"], "titles": ["Welcome to Weelex\u2019s documentation!", "weelex package"], "terms": {"index": 0, "modul": 0, "search": 0, "page": 0, "packag": [], "submodul": [], "base": [], "classifi": [], "cli": [], "embed": [], "ensembl": [], "lexicon": [], "lsx": [], "predictor": [], "tfidf": [], "trainer": [], "content": [], "class": 1, "embedding_dict": 1, "option": 1, "dict": 1, "str": 1, "float": 1, "none": 1, "testvalu": 1, "test": 1, "sourc": 1, "object": 1, "properti": 1, "dim": 1, "filter_term": 1, "term": 1, "union": 1, "list": 1, "ndarrai": 1, "datafram": 1, "tupl": 1, "kei": 1, "classmethod": 1, "load_facebook_vector": 1, "path": 1, "load_filt": 1, "archiv": 1, "zipfil": 1, "load_finetuned_fasttext": 1, "load_finetuned_word2vec": 1, "load_vector": 1, "embedding_typ": 1, "fine_tun": 1, "bool": 1, "fals": 1, "lookup": 1, "seri": 1, "make_wv_from_keys_vector": 1, "save_filt": 1, "augmentedensembl": 1, "categori": 1, "outside_categori": 1, "n_model": 1, "10": 1, "n_samples_multipli": 1, "5": 1, "n_samples_multiplier_outsid": 1, "input_shap": 1, "300": 1, "modeltyp": 1, "svm": 1, "pca": 1, "svc_c": 1, "1": 1, "0": 1, "svc_kernel": 1, "rbf": 1, "progress_bar": 1, "n_vectors_agg_train": 1, "3": 1, "run_fast": 1, "random_st": 1, "modelkwarg": 1, "baseensembl": 1, "baseestim": 1, "train": 1, "an": 1, "model": 1, "For": 1, "each": 1, "random": 1, "select": 1, "input": 1, "vector": 1, "aggreg": 1, "linear": 1, "combin": 1, "augment": 1, "data": 1, "paramet": 1, "sklearn": 1, "estim": 1, "draw_random_samples_classwis": 1, "x": 1, "y": 1, "classvalu": 1, "int": 1, "n_sampl": 1, "include_all_origin": 1, "true": 1, "word": 1, "randomli": 1, "specif": 1, "make": 1, "panda": 1, "The": 1, "matrix": 1, "contain": 1, "valu": 1, "current": 1, "consid": 1, "multipli": 1, "number": 1, "origin": 1, "get": 1, "observ": 1, "shall": 1, "drawn": 1, "sampl": 1, "default": 1, "whether": 1, "i": 1, "e": 1, "non": 1, "includ": 1, "return": 1, "arrai": 1, "can": 1, "us": 1, "machin": 1, "learn": 1, "type": 1, "numpi": 1, "fit": 1, "method": 1, "ml": 1, "via": 1, "pass": 1, "binari": 1, "tell": 1, "belong": 1, "insid": 1, "part": 1, "predict": 1, "outsid": 1, "from": 1, "differ": 1, "one": 1, "A": 1, "form": 1, "target": 1, "load": 1, "filenam": 1, "hyper": 1, "were": 1, "save": 1, "name": 1, "file": 1, "cutoff": 1, "predict_proba": 1, "like": 1, "probabl": 1, "mean": 1, "probabilit": 1, "individu": 1, "disk": 1, "thi": 1, "later": 1, "score": 1, "score_func": 1, "function": 1, "f1_score": 1, "tune": 1, "callabl": 1, "metric": 1, "fullensembl": 1, "param_set": 1, "modelparam": 1, "ensemble_cross_val_scor": 1, "cv": 1, "make_agg_sampl": 1, "n": 1, "draw": 1, "weight": 1, "ensur": 1, "npdarraoth": 1, "add": 1, "up": 1, "simplifi": 1, "just": 1, "integ": 1, "take": 1, "rel": 1, "size": 1, "m": 1, "shape": 1, "onli": 1, "baselexicon": 1, "dictionari": 1, "core": 1, "frame": 1, "sep": 1, "encod": 1, "copi": 1, "emb": 1, "embedding_shap": 1, "get_vocabulari": 1, "sort": 1, "all": 1, "exampl": 1, "my_dct": 1, "food": 1, "bread": 1, "salad": 1, "anim": 1, "dog": 1, "cat": 1, "l": 1, "is_embed": 1, "previous": 1, "instanc": 1, "output": 1, "to_dict": 1, "format": 1, "b": 1, "c": 1, "d": 1, "pair": 1, "vocabulari": 1, "merg": 1, "lexica": 1, "iter": 1, "inplac": 1, "weightedlexicon": 1, "merge_lexica": 1, "basictfidf": 1, "stopwords_fil": 1, "relevant_po": 1, "adj": 1, "adv": 1, "noun": 1, "verb": 1, "min_df": 1, "max_df": 1, "95": 1, "spacy_model": 1, "de_core_news_lg": 1, "build_analyz": 1, "call": 1, "tfidfvector": 1, "doe": 1, "proprocess": 1, "thu": 1, "far": 1, "build_preprocessor": 1, "build_token": 1, "preprocess": 1, "check_fit": 1, "decod": 1, "doc": 1, "fit_transform": 1, "fixed_vocabulary_": 1, "get_feature_nam": 1, "get_feature_names_out": 1, "input_featur": 1, "get_param": 1, "deep": 1, "get_stop_word": 1, "idf_": 1, "inverse_transform": 1, "zip_arch": 1, "set_param": 1, "param": 1, "stop_words_": 1, "transform": 1, "vocabulary_": 1, "tfidfclean": 1, "transformermixin": 1, "static": 1, "remove_url": 1, "text": 1, "remov": 1, "url": 1, "found": 1, "string": 1, "regular": 1, "express": 1, "tfidf_cleanup": 1, "basepredictor": 1, "ctfidf": 1, "clustertfidfvector": 1, "use_tfidf": 1, "use_ctfidf": 1, "word_level_aggreg": 1, "n_job": 1, "n_doc": 1, "2000000": 1, "corpus_path": 1, "corpus_path_encod": 1, "latin1": 1, "load_clust": 1, "checkterm": 1, "politik": 1, "n_top_clust": 1, "cluster_shar": 1, "2": 1, "clustermethod": 1, "agglom": 1, "distance_threshold": 1, "n_word": 1, "40000": 1, "embedding_dim": 1, "fit_ctfidf": 1, "fit_tfidf": 1, "If": 1, "subobject": 1, "ar": 1, "map": 1, "is_fit": 1, "weelexclassifi": 1, "test_siz": 1, "train_param": 1, "lex": 1, "support_lex": 1, "main_kei": 1, "support_kei": 1, "hp_tune": 1, "n_iter": 1, "150": 1, "param_grid": 1, "fixed_param": 1, "n_best_param": 1, "predict_doc": 1, "n_batch": 1, "checkpoint_path": 1, "predict_proba_doc": 1, "predict_proba_word": 1, "predict_word": 1, "set": 1, "work": 1, "simpl": 1, "well": 1, "nest": 1, "pipelin": 1, "latter": 1, "have": 1, "compon": 1, "__": 1, "so": 1, "s": 1, "possibl": 1, "updat": 1, "self": 1, "weelexcli": 1, "main": 1, "parse_arg": 1, "latentsemanticsc": 1, "scale_result": 1, "scaler": 1, "standard": 1, "doc_polar": 1, "polarity_lexicon": 1, "polar": 1, "predict_vector": 1, "predictionprocessor": 1, "aggregate_word_level": 1, "keepword": 1, "load_ctfidf": 1, "load_from_weelexarch": 1, "load_tfidf": 1, "save_ctfidf": 1, "dir": 1, "save_tfidf": 1, "trainprocessor": 1, "feed_cat_xi": 1, "make_train_test_data": 1}, "objects": {"": [[1, 0, 0, "-", "weelex"]], "weelex": [[1, 0, 0, "-", "base"], [1, 0, 0, "-", "classifier"], [1, 0, 0, "-", "cli"], [1, 0, 0, "-", "embeddings"], [1, 0, 0, "-", "ensemble"], [1, 0, 0, "-", "lexicon"], [1, 0, 0, "-", "lsx"], [1, 0, 0, "-", "predictor"], [1, 0, 0, "-", "tfidf"], [1, 0, 0, "-", "trainer"]], "weelex.base": [[1, 1, 1, "", "BasePredictor"]], "weelex.base.BasePredictor": [[1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "fit_ctfidf"], [1, 3, 1, "", "fit_tfidf"], [1, 3, 1, "", "get_params"], [1, 2, 1, "", "is_fit"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 2, 1, "", "vocabulary"]], "weelex.classifier": [[1, 1, 1, "", "WEELexClassifier"]], "weelex.classifier.WEELexClassifier": [[1, 3, 1, "", "fit"], [1, 3, 1, "", "load"], [1, 2, 1, "", "main_keys"], [1, 3, 1, "", "predict_docs"], [1, 3, 1, "", "predict_proba_docs"], [1, 3, 1, "", "predict_proba_words"], [1, 3, 1, "", "predict_words"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "support_keys"], [1, 2, 1, "", "vocabulary"]], "weelex.cli": [[1, 1, 1, "", "WEELexCli"], [1, 4, 1, "", "parse_args"]], "weelex.cli.WEELexCli": [[1, 3, 1, "", "fit"], [1, 3, 1, "", "main"], [1, 3, 1, "", "predict"]], "weelex.embeddings": [[1, 1, 1, "", "Embeddings"]], "weelex.embeddings.Embeddings": [[1, 2, 1, "", "dim"], [1, 3, 1, "", "filter_terms"], [1, 2, 1, "", "keys"], [1, 3, 1, "", "load_facebook_vectors"], [1, 3, 1, "", "load_filtered"], [1, 3, 1, "", "load_finetuned_fasttext"], [1, 3, 1, "", "load_finetuned_word2vec"], [1, 3, 1, "", "load_vectors"], [1, 3, 1, "", "lookup"], [1, 3, 1, "", "make_wv_from_keys_vectors"], [1, 3, 1, "", "save_filtered"]], "weelex.ensemble": [[1, 1, 1, "", "AugmentedEnsemble"], [1, 1, 1, "", "BaseEnsemble"], [1, 1, 1, "", "FullEnsemble"], [1, 4, 1, "", "ensemble_cross_val_score"], [1, 4, 1, "", "make_agg_sample"]], "weelex.ensemble.AugmentedEnsemble": [[1, 3, 1, "", "draw_random_samples_classwise"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "load"], [1, 3, 1, "", "predict"], [1, 3, 1, "", "predict_proba"], [1, 3, 1, "", "save"], [1, 3, 1, "", "score"]], "weelex.ensemble.FullEnsemble": [[1, 3, 1, "", "fit"], [1, 3, 1, "", "load"], [1, 3, 1, "", "predict"], [1, 3, 1, "", "predict_proba"], [1, 3, 1, "", "save"]], "weelex.lexicon": [[1, 1, 1, "", "BaseLexicon"], [1, 1, 1, "", "Lexicon"], [1, 1, 1, "", "WeightedLexicon"], [1, 4, 1, "", "load"], [1, 4, 1, "", "merge_lexica"]], "weelex.lexicon.BaseLexicon": [[1, 3, 1, "", "copy"], [1, 3, 1, "", "embed"], [1, 2, 1, "", "embedding_shape"], [1, 2, 1, "", "embeddings"], [1, 3, 1, "", "get_vocabulary"], [1, 2, 1, "", "is_embedded"], [1, 2, 1, "", "keys"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 3, 1, "", "to_dict"], [1, 2, 1, "", "vocabulary"]], "weelex.lexicon.Lexicon": [[1, 3, 1, "", "merge"]], "weelex.lexicon.WeightedLexicon": [[1, 3, 1, "", "embed"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 3, 1, "", "to_dict"], [1, 2, 1, "", "vocabulary"], [1, 2, 1, "", "weights"]], "weelex.lsx": [[1, 1, 1, "", "LatentSemanticScaling"]], "weelex.lsx.LatentSemanticScaling": [[1, 3, 1, "", "doc_polarity"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "load"], [1, 3, 1, "", "polarity"], [1, 3, 1, "", "predict_docs"], [1, 3, 1, "", "predict_vectors"], [1, 3, 1, "", "predict_words"]], "weelex.predictor": [[1, 1, 1, "", "PredictionProcessor"]], "weelex.predictor.PredictionProcessor": [[1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_ctfidf"], [1, 3, 1, "", "fit_tfidf"], [1, 3, 1, "", "load"], [1, 3, 1, "", "load_ctfidf"], [1, 3, 1, "", "load_from_weelexarchive"], [1, 3, 1, "", "load_tfidf"], [1, 3, 1, "", "save"], [1, 3, 1, "", "save_ctfidf"], [1, 3, 1, "", "save_tfidf"], [1, 3, 1, "", "transform"]], "weelex.tfidf": [[1, 1, 1, "", "BasicTfidf"], [1, 1, 1, "", "TfidfCleaner"], [1, 4, 1, "", "remove_urls"], [1, 4, 1, "", "tfidf_cleanup"]], "weelex.tfidf.BasicTfidf": [[1, 3, 1, "", "build_analyzer"], [1, 3, 1, "", "build_preprocessor"], [1, 3, 1, "", "build_tokenizer"], [1, 3, 1, "", "check_fit"], [1, 3, 1, "", "decode"], [1, 3, 1, "", "fit"], [1, 3, 1, "", "fit_transform"], [1, 2, 1, "", "fixed_vocabulary_"], [1, 3, 1, "", "get_feature_names"], [1, 3, 1, "", "get_feature_names_out"], [1, 3, 1, "", "get_params"], [1, 3, 1, "", "get_stop_words"], [1, 2, 1, "", "idf_"], [1, 3, 1, "", "inverse_transform"], [1, 3, 1, "", "load"], [1, 3, 1, "", "save"], [1, 3, 1, "", "set_params"], [1, 2, 1, "", "stop_words_"], [1, 3, 1, "", "transform"], [1, 2, 1, "", "vocabulary_"]], "weelex.tfidf.TfidfCleaner": [[1, 3, 1, "", "fit"], [1, 3, 1, "", "transform"]], "weelex.trainer": [[1, 1, 1, "", "TrainProcessor"]], "weelex.trainer.TrainProcessor": [[1, 2, 1, "", "embedding_dim"], [1, 3, 1, "", "feed_cat_Xy"], [1, 2, 1, "", "main_keys"], [1, 3, 1, "", "make_train_test_data"], [1, 2, 1, "", "support_keys"], [1, 3, 1, "", "transform"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "weelex": [0, 1], "s": 0, "document": 0, "indic": 0, "tabl": 0, "packag": 1, "submodul": 1, "base": 1, "modul": 1, "classifi": 1, "cli": 1, "embed": 1, "ensembl": 1, "lexicon": 1, "lsx": 1, "predictor": 1, "tfidf": 1, "trainer": 1, "content": 1}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})